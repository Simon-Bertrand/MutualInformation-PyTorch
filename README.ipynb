{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python library : torch_mi\n",
    "\n",
    "The torch_mi library provides implementations of three different methods for calculating Mutual Information:\n",
    "\n",
    "- KNN (K-Nearest Neighbors)\n",
    "- KDE (Kernel Density Estimation)\n",
    "- Vectorized bins count method that can be differentiable.\n",
    "\n",
    "These methods can be used to measure the amount of information shared between two variables in a dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References :\n",
    "\n",
    "- [KNN] \"Estimating Mutual Information\", Alexander Kraskov, Harald Stoegbauer, Peter Grassberger - https://arxiv.org/abs/cond-mat/0305641\n",
    "\n",
    "- [Bins] https://en.wikipedia.org/wiki/Mutual_information\n",
    "\n",
    "- [KDE] \"Estimation of Mutual Information Using Kernel Density Estimators\", Moon, Young-Il & Rajagopalan, Balaji & Lall, Upmanu - https://www.researchgate.net/publication/13324976_Estimation_of_Mutual_Information_Using_Kernel_Density_Estimators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install https://github.com/Simon-Bertrand/MutualInformation-PyTorch/archive/main.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some data and define some utils functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def createCovMat(stdX, stdY, p):\n",
    "    return torch.tensor([[stdX**2, p * stdX * stdY], [p * stdX * stdY, stdY**2]])\n",
    "\n",
    "\n",
    "def miGroundTruth(covMat):\n",
    "    r = covMat[0, 1] / covMat.diag().prod().sqrt()\n",
    "    return -1 / 2 * math.log(1 - r**2)\n",
    "\n",
    "\n",
    "def entropyGroundTruth(covMat):\n",
    "    r = covMat[0, 1] / torch.diag(covMat).prod().sqrt()\n",
    "    return (\n",
    "        1 / 2 + 1 / 2 * math.log(2 * math.pi) + math.log(covMat[0, 0].sqrt()),\n",
    "        1 / 2 + 1 / 2 * math.log(2 * math.pi) + math.log(covMat[1, 1].sqrt()),\n",
    "        1\n",
    "        + math.log(2 * math.pi)\n",
    "        + math.log(torch.diag(covMat).prod().sqrt())\n",
    "        + 1 / 2 * math.log(1 - r**2),\n",
    "    )\n",
    "\n",
    "\n",
    "def getMultivariateNormal(covMat, meanX, meanY):\n",
    "    return MultivariateNormal(torch.Tensor([meanX, meanY]), covMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "nNeighbours = 3\n",
    "nBins = 20\n",
    "\n",
    "# Define data parameters and generate it\n",
    "r = 0.50\n",
    "means = [1, 1]\n",
    "covMat = createCovMat(1, 1, r)\n",
    "B, C, H, W = 1, 1, 32, 32\n",
    "x, y = getMultivariateNormal(covMat, *means).sample((B, C, H, W)).moveaxis(-1, 0)\n",
    "\n",
    "# Print ground truth mutual information for the normal multivariate case\n",
    "print(\"Ground truth MI:\", miGroundTruth(covMat))\n",
    "\n",
    "# Instanciate four methods\n",
    "binsMiSoft = torch_mi.BinsCountMutualInformation(nBins=nBins, mode=\"soft\")  # Default mode\n",
    "binsMiDiscrete = torch_mi.BinsCountMutualInformation(nBins=nBins, mode=\"discrete\")\n",
    "kdeMi = torch_mi.KdeMutualInformation(nBins=nBins)\n",
    "knnMi = torch_mi.KnnMutualInformation(nNeighbours=nNeighbours)\n",
    "\n",
    "BC, HW = x.size(0) * x.size(1), x.size(2) * x.size(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot density based joint distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3)\n",
    "axes[0].imshow(kdeMi.computePxy(x.view(BC, HW), y.view(BC, HW))[0])\n",
    "axes[1].imshow(binsMiSoft.computePxy(x.view(BC, HW), y.view(BC, HW))[0])\n",
    "axes[2].imshow(binsMiDiscrete.computePxy(x.view(BC, HW), y.view(BC, HW))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Mutual Information for each method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(\n",
    "    binsMiSoft=binsMiSoft(x, y),\n",
    "    binsMiDiscrete=binsMiDiscrete(x, y),\n",
    "    kdeMi=kdeMi(x, y),\n",
    "    knnMi=knnMi(x, y),\n",
    "    gt=miGroundTruth(covMat),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute some stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "nRealizations = 32\n",
    "\n",
    "\n",
    "def task(args):\n",
    "    r, n = args\n",
    "    covMat = createCovMat(1, 1, r)\n",
    "    means = [0, 0]\n",
    "    x, y = getMultivariateNormal(covMat, *means).sample((nRealizations, 1, n, n)).moveaxis(-1, 0)\n",
    "    start = time.time()\n",
    "    knn = knnMi(x, y).mean()\n",
    "    knnTime = 1000 * (time.time() - start) / nRealizations\n",
    "\n",
    "    start = time.time()\n",
    "    kde = kdeMi(x, y).mean()\n",
    "    kdeTime = 1000 * (time.time() - start) / nRealizations\n",
    "\n",
    "    start = time.time()\n",
    "    bins = binsMiSoft(x, y).mean()\n",
    "    binsTime = 1000 * (time.time() - start) / nRealizations\n",
    "\n",
    "    return {\n",
    "        \"n\": float(n**2),\n",
    "        \"r\": float(r),\n",
    "        \"gt\": float(miGroundTruth(covMat)),\n",
    "        **dict(zip([\"varX\", \"varY\"], covMat.diag().tolist())),\n",
    "        **dict(zip([\"meanX\", \"meanY\"], means)),\n",
    "        \"knn:score\": float(knn),\n",
    "        \"kde:score\": float(kde),\n",
    "        \"bins:score\": float(bins),\n",
    "        \"knn:duration\": float(knnTime),\n",
    "        \"kde:duration\": float(kdeTime),\n",
    "        \"bins:duration\": float(binsTime),\n",
    "    }\n",
    "\n",
    "\n",
    "rs = torch.linspace(0.1, 0.99, 10)\n",
    "N = torch.logspace(1, 1.9, 10).to(torch.int)\n",
    "\n",
    "stats = pd.DataFrame(\n",
    "    list(\n",
    "        tqdm(\n",
    "            map(task, ((r, n) for r in rs for n in N)),\n",
    "            total=len(rs) * len(N),\n",
    "        )\n",
    "    )\n",
    ").assign(\n",
    "    **{\n",
    "        \"knn:score_err\": lambda x: (x[\"knn:score\"].mean() - x[\"gt\"]) / (x[\"gt\"].abs()),\n",
    "        \"kde:score_err\": lambda x: (x[\"kde:score\"].mean() - x[\"gt\"]) / (x[\"gt\"].abs()),\n",
    "        \"bins:score_err\": lambda x: (x[\"bins:score\"].mean() - x[\"gt\"]) / (x[\"gt\"].abs()),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot method precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.plot(x=\"gt\", y=[\"knn:score\", \"kde:score\", \"bins:score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot method dependency with the correlation coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby(\"r\").agg(\n",
    "    {\n",
    "        \"knn:score\": \"mean\",\n",
    "        \"kde:score\": \"mean\",\n",
    "        \"bins:score\": \"mean\",\n",
    "        \"gt\": \"mean\",\n",
    "    }\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show mean error depending on sample size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby(\"n\").agg(\n",
    "    {\n",
    "        \"knn:score_err\": \"mean\",\n",
    "        \"kde:score_err\": \"mean\",\n",
    "        \"bins:score_err\": \"mean\",\n",
    "    }\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show method durations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby(\"n\").agg(\n",
    "    {\n",
    "        \"knn:duration\": \"mean\",\n",
    "        \"kde:duration\": \"mean\",\n",
    "        \"bins:duration\": \"mean\",\n",
    "    }\n",
    ").plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
